#!/usr/bin/env python

import sys
from topik.tokenizers import ngrams
from nltk.tokenize.punkt import PunktSentenceTokenizer
from nltk.tokenize import WhitespaceTokenizer
from nltk.corpus import webtext


input = ' '.join(sys.argv[1:])
text = webtext.raw('appliances.txt')

#sent_tokenizer = PunktSentenceTokenizer(text)
#print sent_tokenizer.tokenize(input)
word_tokenizer = WhitespaceTokenizer()
print word_tokenizer.tokenize(input)
